import io
import json
import re
import typing
from pathlib import Path

import numpy as np
import pandas as pd

from .dataset import DatasetArtefact, DatasetName, Field
from .json import JSONDataSetContainer


class PidMapDataset(JSONDataSetContainer):
    """
    JSON output generated by the --libxo option of the ps command
    Currently we only support a subset of the output values
    """
    dataset_config_name = DatasetName.PIDMAP
    dataset_source_id = DatasetArtefact.PIDMAP
    fields = [
        Field("pid", dtype=int),
        Field("tid", dtype=int),
        Field.str_field("command"),
        Field.str_field("thread_name")
    ]

    def __init__(self, benchmark, dset_key, config):
        super().__init__(benchmark, dset_key, config)
        self._pid_snapshot = {}

    def resolve_user_binaries(self, dataset_id) -> pd.DataFrame:
        df = self.df.xs(dataset_id)
        P_KPROC_MASK = 0x4
        user_commands = (df["flags"] & P_KPROC_MASK) == 0

        def resolve_path(cmd):
            target_path = Path(cmd)
            if target_path.is_absolute():
                return self.benchmark.rootfs / target_path.relative_to("/")
            else:
                # attempt to locate file in /bin /usr/bin /usr/sbin
                dollarpath = [Path("bin"), Path("usr/bin"), Path("usr/sbin")]
                for path in dollarpath:
                    candidate = self.benchmark.rootfs / path / target_path
                    if candidate.exists():
                        return candidate
            return None

        result_df = df.copy()
        result_df["command"] = df["command"].map(resolve_path)
        return result_df[~result_df["command"].isna()]

    def output_file(self):
        return super().output_file().with_suffix(".json")

    def load(self):
        path = self.output_file()
        with open(path, "r") as fd:
            data_map = json.load(fd)
        # normalize records in the json first to use lists instead of dicts
        data = list(data_map.values())
        for proc_desc in data:
            proc_desc["threads"] = list(proc_desc["threads"].values())
        # generate the normalized dataframe from hierarchical data
        pid_info = pd.json_normalize(data)
        tid_info = pd.json_normalize(data, "threads", ["process_id"])
        df = pid_info.merge(tid_info, how="left", left_on="process_id", right_on="process_id")
        df.rename(columns={"process_id": "pid", "thread_id": "tid"}, inplace=True)
        df["tid"].fillna(-1, inplace=True)
        df["dataset_id"] = self.benchmark.uuid
        self._append_df(df)

    def load_from_kdump(self, kdump_fd):
        """
        Add a system PID sample to the dataset from the output of kdump
        We inspect the output for fork() syscalls
        """
        cols = ["pid", "command", "op", "args"]
        rows = []
        for line in kdump_fd:
            rows.append(re.split("\s+", line.lstrip(), len(cols) - 1))
        kdump_df = pd.DataFrame.from_records(rows, columns=cols)
        forks = (kdump_df["op"] == "RET") & (kdump_df["args"].str.startswith("fork"))
        fork_df = kdump_df[forks].reset_index(drop=True)
        # fork return is in the form "fork <pid>/<hex-pid>"
        fork_df["child_pid"] = fork_df["args"].map(lambda arg: arg.split(" ")[1].split("/")[0])
        pid_df = fork_df[["child_pid", "command"]].rename(columns={"child_pid": "pid"})
        pid_df["tid"] = -1
        pid_df["thread_name"] = ""
        pid_df["dataset_id"] = self.benchmark.uuid
        # Assume that the pids do not overlap
        self._append_df(pid_df)

    def fixup_missing_tid(self, tid_mapping: pd.DataFrame) -> pd.DataFrame:
        """
        Return a copy of the main dataframe replacing the missing TID values
        using the given mapping dataframe.
        """
        assert "pid" in tid_mapping.columns
        assert "tid" in tid_mapping.columns
        tid_mapping = tid_mapping.add_suffix("_fixup")

        missing_tid = self.df["tid"] == -1
        matched_tid = self.df[~missing_tid]
        guess_tid = self.df[missing_tid].merge(tid_mapping, how="left", left_on="pid", right_on="pid_fixup")
        guess_tid["tid"] = guess_tid["tid_fixup"].fillna(-1).astype(int)
        fixup_df = pd.concat((matched_tid, guess_tid[self.input_non_index_columns()]))
        return fixup_df

    def _merge_procstat_entry(self, entry: dict):
        pid = entry["process_id"]
        if str(pid) in self._pid_snapshot:
            snap_entry = self._pid_snapshot[pid]
            # Currently, do not support PID/TID reuse
            if snap_entry["command"] != entry["command"]:
                self.logger.error("System PID snapshot repeated PID conflict %d: %s != %s", entry["process_id"],
                                  entry["command"], snap_entry["command"])
                return
            for tid, thr_entry in entry["threads"].items():
                if tid in snap_entry["threads"]:
                    snap_thr_entry = snap_entry["threads"][tid]
                    if snap_thr_entry["thread_name"] != thr_entry["thread_name"]:
                        self.logger.error("System PID snapshot repeated TID conflict for %s %d: %s != %s",
                                          entry["command"], thr_entry["thread_id"], thr_entry["thread_name"],
                                          snap_thr_entry["thread_name"])
                        continue
                else:
                    snap_entry["threads"][tid] = thr_entry
        else:
            self._pid_snapshot[pid] = entry

    def sample_system_pids(self):
        """
        Add a system PID sample to the output data.
        This is exposed to other datasets so that snapshots can be taken at interesting
        times.
        """
        self.logger.debug("Generate system PIDs sampling command")
        self._script.gen_cmd("procstat", ["-a", "-t", "--libxo", "json"],
                             outfile=self.output_file(),
                             extractfn=self._extract_pid_sample)

    async def _extract_pid_sample(self, remote_path, local_path):
        # Merge the PIDs with any existing sample.
        self.logger.info("Extract system PIDs")
        pid_raw_data = io.StringIO()
        await self.benchmark.read_remote_file(remote_path, pid_raw_data)
        self.logger.debug(pid_raw_data.getvalue())
        raw_data = json.loads(pid_raw_data.getvalue())
        proc_map = raw_data["procstat"]["threads"]
        for pid, info in proc_map.items():
            self._merge_procstat_entry(info)

    async def after_extract_results(self):
        await super().after_extract_results()
        # Grab the command history and merge it as well
        cmd_pids = pd.read_csv(self._script.command_history_path(), index_col=False, names=["pid"])
        cmd_pids["command"] = self._script.get_commands_with_pid()
        for _, row in cmd_pids.iterrows():
            entry = {
                "process_id": row["pid"],
                "command": str(row["command"]),
                # We do not have thread info for these, should really use a different method
                "threads": {}
            }
            self._merge_procstat_entry(entry)

        with open(self.output_file(), "w+") as pid_fd:
            json.dump(self._pid_snapshot, pid_fd)

    def gen_post_benchmark(self):
        """
        Post-benchmark hook to extract PID mappings.
        Note: we also use the command history from the benchmark runner to resolve any
        extra processes we have been running and that have since terminated.
        """
        super().gen_post_benchmark()
        self.sample_system_pids()
